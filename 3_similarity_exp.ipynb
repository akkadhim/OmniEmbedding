{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import spearmanr\n",
    "from tools import Tools\n",
    "import tqdm\n",
    "\n",
    "target_similarity=defaultdict(list)\n",
    "\n",
    "def calculate(self, target_similarity, pair_list):\n",
    "    calculated_score=[]\n",
    "    extracted_list = []\n",
    "    original_score=[]\n",
    "    word_pairs=[]\n",
    "    \n",
    "    for (x,y) in pair_list:\n",
    "        if x in target_similarity:\n",
    "            word1, word2=x\n",
    "            word1_prof = target_similarity[x] \n",
    "            extracted_list.append((x, word1_prof))\n",
    "            calculated_score.append(word1_prof)\n",
    "            original_score.append(y)\n",
    "            word_pairs.append(x)\n",
    "\n",
    "    spearman_TM = spearmanr(original_score, calculated_score)\n",
    "    spearman_TM = round(spearman_TM[0], 3)\n",
    "    print(f'Spearman TM: {spearman_TM}')\n",
    "\n",
    "    total_list=[]\n",
    "    total_list.append(original_score)\n",
    "    total_list.append(calculated_score)\n",
    "\n",
    "    similarity = cosine_similarity(total_list)\n",
    "    print(f'Cosine TM \\n{similarity}')\n",
    "\n",
    "    TM_corr= np.corrcoef(original_score, calculated_score)\n",
    "    print(f'Pearson TM \\n{TM_corr}')\n",
    "\n",
    "    kendal_TM, _ = kendalltau(original_score, calculated_score)\n",
    "    print(f'Kendal TM: {kendal_TM}')\n",
    "\n",
    "    data = pd.DataFrame([original_score,calculated_score])\n",
    "    data=data.transpose()\n",
    "    data.columns=['Original','TM']\n",
    "    correlation = data.corr()\n",
    "    print(\"Pearson Corr \\n\", correlation)\n",
    "    return spearman_TM\n",
    "\n",
    "vectorizer_X = Tools.read_pickle_data(\"vectorizer_X.pickle\")\n",
    "number_of_features = vectorizer_X.get_feature_names_out().shape[0]\n",
    "feature_names = vectorizer_X.get_feature_names_out()\n",
    "omni_embeddings = Tools.read_pickle_data(\"omni_embeddings.pickle\")\n",
    "\n",
    "target_dataset_name = \"rg-65\"\n",
    "# target_dataset_name = \"wordsim353-sim\"\n",
    "# target_dataset_name = \"mturk-287\"\n",
    "# target_dataset_name = \"mturk-771\"\n",
    "# target_dataset_name = \"simlex999\"\n",
    "# target_dataset_name = \"men\"\n",
    "\n",
    "pair_list = Tools.get_dataset_pairs(target_dataset_name)\n",
    "output_active, target_words = Tools.get_dataset_targets(target_dataset_name, vectorizer_X, pair_list)\n",
    "print(f\"Dataset: {target_dataset_name}, Number of pairs: {len(pair_list)}, Number of words: {len(target_words)}\")\n",
    "token_embeddings = {}\n",
    "for word in tqdm.tqdm(target_words, desc=\"Loading token embeddings\"):\n",
    "    word_id = vectorizer_X.vocabulary_.get(word, None)\n",
    "    if word_id is not None:\n",
    "        token_embeddings[word_id] = omni_embeddings[word]\n",
    "\n",
    "profile = np.empty((len(target_words), number_of_features))\n",
    "for i, word in enumerate(target_words):\n",
    "    word_id = vectorizer_X.vocabulary_.get(word, None)\n",
    "    if word_id is not None and word_id in token_embeddings:\n",
    "        profile[i, :] = token_embeddings[word_id]\n",
    "    else:\n",
    "        print(f\"Word '{word}' not found in vocabulary or embeddings.\")\n",
    "\n",
    "for i, word1 in enumerate(target_words):\n",
    "    for j, word2 in enumerate(target_words):\n",
    "        if i != j:\n",
    "            word2_index = vectorizer_X.vocabulary_.get(word2, None)\n",
    "            if word2_index is not None:\n",
    "                target_similarity[(word1, word2)] = profile[i, word2_index]\n",
    "            else:\n",
    "                target_similarity[(word1, word2)] = 0.0\n",
    "\n",
    "spearman = calculate(target_similarity,pair_list)\n",
    "token_embeddings = None"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
